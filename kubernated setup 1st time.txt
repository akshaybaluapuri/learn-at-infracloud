
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

sudo add-apt-repository \
   "deb [arch=amd64] https://download.docker.com/linux/ubuntu \
   $(lsb_release -cs) \
   stable"

sudo apt-get update

sudo apt-get install -y docker-ce=18.06.1~ce~3-0~ubuntu

sudo apt-mark hold docker-ce





curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -

cat << EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF

sudo apt-get update

sudo apt-get install -y kubelet=1.12.7-00 kubeadm=1.12.7-00 kubectl=1.12.7-00

sudo apt-mark hold kubelet kubeadm kubectl


bootstraping cluster
Flannel for network setup


kubectl create –f Tesing_for_Image_pull
kubectl log Tesing_for_Image_pull
kubectl create –f py.yaml
kubectl describe jobs/py

$ kubectl create –f namespace.yml ---------> 1
$ kubectl get namespace -----------------> 2
$ kubectl get namespace <Namespace name> ------->3
$ kubectl describe namespace <Namespace name> ---->4
$ kubectl delete namespace <Namespace name>

ClusterIP --> within cluster
NodePort  --> expose service to static IP and port
Load Balancer

> Replica Set ensures how many replica of pod should be running. It can be considered as a replacement of replication controller. The key difference between the replica set and the replication controller is, the replication controller only supports equality-based selector whereas the replica set supports set-based selector.

> Deployments are upgraded and higher version of replication controller. They manage the deployment of replica sets which is also an upgraded version of the replication controller. They have the capability to update the replica set and are also capable of rolling back to the previous version.

> kubectl create –f Deployment.yaml -–record

> kubectl get deployments
> kubectl rollout status deployment/Deployment
> ubectl set image deployment/Deployment tomcat=tomcat:6.0
> kubectl rollout undo deployment/Deployment –to-revision=2

Pod -> PVC -> PV -> Host machine
>  kubectl create –f local-01.yaml
>  kubectl get pv
>  kubectl get pvc
>  kubectl describe pv pv0001


```
cat << EOF | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
EOF
```

```
apiVersion: v1
kind: Pod
metadata:
  name: my-args-pod
  labels:
    app: myapp
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['echo']
    args: ['This is my custom argument']
  restartPolicy: Never
  ```

kubectl get pods
kubectl get pod <pod name> -O wide // for more imp info in single line 
kubectl describe pod nginx
kubectl delete pod nginx
kubectl get pods --all-namespaces // --all-namespaces is option 


```
cat << EOF | kubectl create -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.15.4
        ports:
        - containerPort: 80
EOF
```

```
cat << EOF | kubectl create -f -
apiVersion: v1
kind: Pod
metadata:
  name: busybox
spec:
  containers:
  - name: busybox
    image: radial/busyboxplus:curl
    args:
    - sleep
    - "1000"
EOF
```

kubectl get deployments
kubectl describe deployment nginx-deployment
kubectl get pods -o wide
kubectl exec busybox -- curl $nginx_pod_ip


kubectl delete -f nginx.yaml -f redis.yaml
kubectl replace -f nginx.yaml
kubectl diff -f configs/  #what change will go on
kubectl apply -f configs/

kubectl diff -R -f configs/
kubectl apply -R -f configs/

// Get a list of system pods running in the cluster (namespace):
kubectl get pods -n kube-system
ESOps
silos

Types of service
 - nodePort
 - ClusterIP
 - LoadBalancer

```
cat << EOF | kubectl create -f -
kind: Service
apiVersion: v1
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
  - protocol: TCP
    port: 8080 // host port
    targetPort: 80 // container port
    nodePort: 30080  //You’ll be able to contact the NodePort Service, from outside the cluster, by requesting <NodeIP>:<NodePort>.,  a NodePort in the range of 30000 - 32767 and an internal cluster IP address is assigned to the service.
  type: NodePort
EOF
```
kubectl get svc
kubectl get endpoints my-service or kubectl get ep my-service


kubectl create namespace robot-shop
kubectl -n robot-shop create -f ~/robot-shop/K8s/descriptors/
kubectl get pods -n robot-shop
kubectl get pods -n robot-shop -w (w: to allow to watch changes to it, to know which parts are taking time to start)


kubectl create ns my-ns
kubectl get namespaces

```
apiVersion: v1
kind: Pod
metadata:
  name: my-ns-pod
  namespace: my-ns     <---
  labels:
    app: myapp
spec: ....
```


## Config map
ConfigMap.yml
  apiVersion: v1
  kind: ConfigMap
  metadata:
     name: my-config-map
  data:
     myKey: myValue
     anotherKey: anotherValue
$ kubectl apply -f ConfigMap.yml




apiVersion: v1
kind: Pod
metadata:
  name: my-configmap-pod
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', "echo $(MY_VAR) && sleep 3600"]
    env:
    - name: MY_VAR
      valueFrom:
        configMapKeyRef:
          name: my-config-map
          key: myKey

apiVersion: v1
kind: Pod
metadata:
  name: my-configmap-volume-pod
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', "echo $(cat /etc/config/myKey) && sleep 3600"]
    volumeMounts:
      - name: config-volume
        mountPath: /etc/config
  volumes:
    - name: config-volume
      configMap:
        name: my-config-map


kubectl logs my-configmap-pod
kubectl logs my-configmap-volume-pod
kubectl exec my-configmap-volume-pod -- ls /etc/config
kubectl exec my-configmap-volume-pod -- cat /etc/config/myKey    

kubectl logs <pod_name> -c <container_name_inside_that_pod> // this option required for a multicontainer pod


## Security context

apiVersion: v1
kind: Pod
metadata:
  name: my-securitycontext-pod
spec:
  securityContext:
    runAsUser: 2001
    fsGroup: 3001
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', "cat /message/message.txt && sleep 3600"]
    volumeMounts:
    - name: message-volume
      mountPath: /message
  volumes:
  - name: message-volume
    hostPath:
      path: /etc/message




# Resource Requirements (limits)

apiVersion: v1
kind: Pod
metadata:
  name: my-resource-pod
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', 'echo Hello Kubernetes! && sleep 3600']
    resources:
      requests:
        memory: "64Mi"
        cpu: "250m"
      limits:
        memory: "128Mi"
        cpu: "500m"


### Secret
apiVersion: v1
kind: Secret
metadata:
  name: my-secret
stringData:
  myKey: myPassword
 (similar to config map apply this secret instand to create)

apiVersion: v1
kind: Pod
metadata:
  name: my-secret-pod
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', "echo Hello, Kubernetes! && sleep 3600"]
    env:
    - name: MY_PASSWORD
      valueFrom:
        secretKeyRef:
          name: my-secret
          key: myKey


## service account
kubectl create serviceaccount my-serviceaccount

apiVersion: v1
kind: Pod
metadata:
  name: my-serviceaccount-pod
spec:
  serviceAccountName: my-serviceaccount
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', "echo Hello, Kubernetes! && sleep 3600"]


# emptyDir in volume
apiVersion: v1
kind: Pod
metadata:
  name: volume-pod
spec:
  containers:
  - image: busybox
    name: busybox
    command: ["/bin/sh", "-c", "while true; do sleep 3600; done"]
    volumeMounts:
    - mountPath: /tmp/storage
      name: my-volume
  volumes:
  - name: my-volume
    emptyDir: {}



# 3 ways for containers within same pod can communicate
- shared network (simply by localhost:port no)
- shared storage volume
- shared process namespace (by setting -> sharedProcessNamespace: True)

# 3 design patterns
- sidecar pattern
- Ambassador pattern 
- Adapter pattern 

# PV and PVC

kind: PersistentVolume
apiVersion: v1
metadata:
  name: my-pv
spec:
  storageClassName: local-storage
  capacity:
    storage: 1Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/mnt/data"

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  storageClassName: local-storage
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 512Mi

kubectl get pv
kubectl get pvc 

kind: Pod
apiVersion: v1
metadata:
  name: my-pvc-pod
spec:
  containers:
  - name: busybox
    image: busybox
    command: ["/bin/sh", "-c", "while true; do sleep 3600; done"]
    volumeMounts:
    - mountPath: "/mnt/storage"
      name: my-storage
  volumes:
  - name: my-storage
    persistentVolumeClaim:
      claimName: my-pvc

# Labels and selector
 kubectl get pods --show-labels // also visible under describe
 kubectl get pods -l app=my-app
 kubectl get pods -l environment=production
 kubectl get pods -l environment=development
 kubectl get pods -l environment!=production
 kubectl get pods -l 'environment in (development,production)'
 kubectl get pods -l app=my-app,environment=production

# Annotation
   => Similar to labels but not intended to be used as selectors, just purpose is to store custom key value pair
   apiVersion: v1
   kind: Pod
   metadata:
     name: my-annotation-pod
     annotations:
       owner: terry@linuxacademy.com
       git-commit: bdab0c6
   spec: ...

# kubectl edit deployment <deployment name> // opens up a file containing deployment, to make any change in deployment


# Roling update and roll back
  kubectl set image deployment/<name of deployment> nginx=nginx:1.7.9 --record  // container_name=update_in_container
  kubectl rollout history deployment/<name of deployment>
  kubectl rollout history deployment/<name of deployment> --revision=2 // for more infor of specific one
  kubectl rollout undo deployment/<name of deployment> // just get back to previous version
  kubectl rollout undo deployment/<name of deployment> --to-revision=1 // get back to specific version
control the rollig update using strategy 
  spec:
   strategy:
     rollingUpdate:
       maxSurge: 3
       maxUnavailable: 2
   replicas: 3


# Jobs, that run container just like pod but unlike pod id not keep on running for always. it contain containers which removed after performing certain tasks, hance jobs are more relaible way to run such containers


apiVersion: batch/v1
kind: Job
metadata:
  name: pi
spec:
  template:
    spec:
      containers:
      - name: pi
        image: perl
        command: ["perl",  "-Mbignum=bpi", "-wle", "print bpi(2000)"]
      restartPolicy: Never
  backoffLimit: 4 // similar to 4 retries on failure before to declare actual failure

  $ kubectl get jobs
  $ kubectl logs <name of pod> // pod still there container is removed

# cron jobs
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
 $ kubectl get cronjobs
 $ kubectl logs <name of pod> // pod still there container is removed


# Network Policy
In order to use NetworkPolicies in the cluster, we need to have a network plugin 
$ wget -O canal.yaml https://docs.projectcalico.org/v3.5/getting-started/kubernetes/installation/hosted/canal/canal.yaml
$ kubectl apply -f canal.yaml

apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: my-network-policy
spec:
  podSelector:
    matchLabels:
      app: secure-app
  policyTypes:  // which will be used in this policy
  - Ingress
  - Egress
  ingress:  // to allow incoming traffic
  - from:
    - podSelector:   // also namespaceSelector, ipBlock (for CIDR block) filters do exists
        matchLabels:
          allow-access: "true"  // to apply on all those pods having this label
    ports:
    - protocol: TCP
      port: 80
  egress:  // to allow outgoing traffic
  - to:
    - podSelector:
        matchLabels:
          allow-access: "true"
    ports:
    - protocol: TCP
      port: 80

kubectl get networkpolicies
kubectl describe networkpolicy my-network-policy


# Probe: help to write custom logic to determine pod is healthy or not (help in spining up new container)
Liveness and Readiness Probes

Liveness probs: logic to determine wather or not container is live (running properly) 
Readiness probe: logic to determine wather or not container is ready to service  request

Examples: 
apiVersion: v1
kind: Pod
metadata:
  name: my-liveness-pod
spec:
  containers:
  - name: myapp-container
    image: busybox
    command: ['sh', '-c', "echo Hello, Kubernetes! && sleep 3600"]
    livenessProbe:
      exec:       // more diffetern types available as httpGet
        command:
        - echo
        - testing
      initialDelaySeconds: 5 // wait this time before to run for the 1st time 
      periodSeconds: 5   // run this every 5 sec



apiVersion: v1
kind: Pod
metadata:
  name: my-readiness-pod
spec:
  containers:
  - name: myapp-container
    image: nginx
    readinessProbe:
      httpGet:
        path: /
        port: 80
      initialDelaySeconds: 5
      periodSeconds: 5


# TOP 
kubectl top pods
kubectl top pod resource-consumer-big
kubectl top pods -n kube-system
kubectl top nodes


# Metrics server: provides APi to access data about resources
git clone https://github.com/linuxacademy/metrics-server
kubectl apply -f ~/metrics-server/deploy/1.8+/  (1.8 from kubernetes version)
kubectl get --raw /apis/metrics.k8s.io/  (--raw to access API directly) and resource data contain cpu and memory usage

# we can not add new fields (eg livenessprob etc) with kubectl edit, we simply need to create new pod in that case, we can only update existing values with this edit feature'
best way to recreate pod is use
kubectl get pod nginx -n nginx-ns -o yaml --export // export only descriptor, not the status in yaml formate, now just edit and create (output doesnt contain namespace value)



